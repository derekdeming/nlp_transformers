{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "Stemming is a *text normalization* method used in NLP to simplify text before it is processed by a model. When stemming break the final few characters of a word in order to find a common form of the word. If we take the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"I am amazed by how amazingly amazing you are\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i am using different forms of the word **amaze** a total of *three* times. Each of these different forms is called an *'inflection'*, which is the modification of a word to slightly adjust the meaning or context of the word. When we tokenize this text we produce three different tokens for each inflection of happy, which is okay but in many applications this level of granularity in the semantic meaning of the word is not required and can damage model performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PorterStemmer paper published in 1979 \n",
    "\n",
    "##### https://tartarus.org/martin/PorterStemmer/def.txt\n",
    "\n",
    "very light weight model with a few conditions and relatively fast \n",
    "=\n",
    "The Porter stemmer should be regarded as ‘frozen’, that is, strictly defined, and not amenable to further modification. As a stemmer, it is slightly inferior to the Snowball English or Porter2 stemmer, which derives from it, and which is subjected to occasional improvements. For practical work, therefore, the new Snowball stemmer is recommended. The Porter stemmer is appropriate to IR research work involving stemming where the experiments need to be exactly repeatable.\n",
    "\n",
    "\n",
    "LancasterStemmer \n",
    "\n",
    "bit more complex containing several more conditions / rules and it doesn't apply each rule 1 after the other, it actually iterates over the list of rules and applies ones that apply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter | Lancaster\n",
      "happi | happy\n",
      "happiest | happiest\n",
      "happier | happy\n",
      "cactu | cact\n",
      "cactii | cacti\n",
      "eleph | eleph\n",
      "eleph | eleph\n",
      "amaz | amaz\n",
      "amaz | amaz\n",
      "amazingli | amaz\n",
      "cement | cem\n",
      "owe | ow\n",
      "maximum | maxim\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "\n",
    "words_to_stem = ['happy', 'happiest', 'happier', 'cactus', 'cactii', 'elephant', 'elephants', 'amazed', 'amazing', 'amazingly', 'cement', 'owed', 'maximum']\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "stemmed = [(porter.stem(word), lancaster.stem(word)) for word in words_to_stem]\n",
    "\n",
    "print(\"Porter | Lancaster\")\n",
    "for stem in stemmed:\n",
    "    print(f\"{stem[0]} | {stem[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
